# **4.2.B Pull Model = Distributed Scheduler**

## Option B is essentially:

```

No central master - each shard scheduler competes for jobs directly.

[Global Job Queue]
      ↓ ↓ ↓ ↓
   [S1][S2][S3][S4]  ← Competing consumers

```

**Tradeoffs:**
- ✅ Simpler (no master bottleneck)
- ✅ Self-regulating (sick shards stop consuming)
- ❌ Less deterministic (can't enforce "put this job on Shard 7")
- ❌ Harder to do global optimizations (GPU affinity across shards)

Option B is a distributed scheduler where shards compete for
work. It's simpler but gives up control - you can't easily say 'this
job needs to run on Shard 7 because that's where the checkpoint is
cached.' We recommend the Move Model for Janus use case."

## Is Option B ever the “right” choice?

Yes — but not for Janus’s core workload.

### Where Option B *is* valid

Competing consumers make sense when:

* jobs are homogeneous
* placement doesn’t matter
* failures are cheap
* throughput > determinism

Examples:

* log processing
* ETL fan-out
* CPU-bound batch work

## Why it’s weaker *here*

For untrusted GPU workloads:

* placement *matters*
* retries are expensive
* fragmentation hurts everyone
* debugging distributed races is painful

---
